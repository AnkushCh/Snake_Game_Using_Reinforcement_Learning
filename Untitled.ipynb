{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\aryaa\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (1.12.0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\aryaa\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from tensorflow) (0.35.1)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in c:\\users\\aryaa\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from tensorflow) (0.10.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in c:\\users\\aryaa\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\aryaa\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: tensorboard<1.13.0,>=1.12.0 in c:\\users\\aryaa\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from tensorflow) (1.12.2)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\aryaa\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\users\\aryaa\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from tensorflow) (1.0.8)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\aryaa\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from tensorflow) (1.31.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in c:\\users\\aryaa\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from tensorflow) (3.13.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in c:\\users\\aryaa\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from tensorflow) (0.8.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\aryaa\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from tensorflow) (1.18.4)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\aryaa\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\aryaa\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in c:\\users\\aryaa\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: h5py in c:\\users\\aryaa\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from keras-applications>=1.0.6->tensorflow) (2.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\aryaa\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages (from protobuf>=3.6.1->tensorflow) (41.2.0)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from operator import add\n",
    "import collections\n",
    "\n",
    "class DQNAgent(object):\n",
    "    def __init__(self, params):\n",
    "        self.reward = 0\n",
    "        self.gamma = 0.9\n",
    "        self.dataframe = pd.DataFrame()\n",
    "        self.short_memory = np.array([])\n",
    "        self.agent_target = 1\n",
    "        self.agent_predict = 0\n",
    "        self.learning_rate = params['learning_rate']        \n",
    "        self.epsilon = 1\n",
    "        self.actual = []\n",
    "        self.first_layer = params['first_layer_size']\n",
    "        self.second_layer = params['second_layer_size']\n",
    "        self.third_layer = params['third_layer_size']\n",
    "        self.memory = collections.deque(maxlen=params['memory_size'])\n",
    "        self.weights = params['weights_path']\n",
    "        self.load_weights = params['load_weights']\n",
    "        self.model = self.network()\n",
    "\n",
    "    def network(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(output_dim=self.first_layer, activation='relu', input_dim=11))\n",
    "        model.add(Dense(output_dim=self.second_layer, activation='relu'))\n",
    "        model.add(Dense(output_dim=self.third_layer, activation='relu'))\n",
    "        model.add(Dense(output_dim=3, activation='softmax'))\n",
    "        opt = Adam(self.learning_rate)\n",
    "        model.compile(loss='mse', optimizer=opt)\n",
    "\n",
    "        if self.load_weights:\n",
    "            model.load_weights(self.weights)\n",
    "        return model\n",
    "    \n",
    "    def get_state(self, game, player, food):\n",
    "        state = [\n",
    "            (player.x_change == 20 and player.y_change == 0 and ((list(map(add, player.position[-1], [20, 0])) in player.position) or\n",
    "            player.position[-1][0] + 20 >= (game.game_width - 20))) or (player.x_change == -20 and player.y_change == 0 and ((list(map(add, player.position[-1], [-20, 0])) in player.position) or\n",
    "            player.position[-1][0] - 20 < 20)) or (player.x_change == 0 and player.y_change == -20 and ((list(map(add, player.position[-1], [0, -20])) in player.position) or\n",
    "            player.position[-1][-1] - 20 < 20)) or (player.x_change == 0 and player.y_change == 20 and ((list(map(add, player.position[-1], [0, 20])) in player.position) or\n",
    "            player.position[-1][-1] + 20 >= (game.game_height-20))),  # danger straight\n",
    "\n",
    "            (player.x_change == 0 and player.y_change == -20 and ((list(map(add,player.position[-1],[20, 0])) in player.position) or\n",
    "            player.position[ -1][0] + 20 > (game.game_width-20))) or (player.x_change == 0 and player.y_change == 20 and ((list(map(add,player.position[-1],\n",
    "            [-20,0])) in player.position) or player.position[-1][0] - 20 < 20)) or (player.x_change == -20 and player.y_change == 0 and ((list(map(\n",
    "            add,player.position[-1],[0,-20])) in player.position) or player.position[-1][-1] - 20 < 20)) or (player.x_change == 20 and player.y_change == 0 and (\n",
    "            (list(map(add,player.position[-1],[0,20])) in player.position) or player.position[-1][\n",
    "             -1] + 20 >= (game.game_height-20))),  # danger right\n",
    "\n",
    "             (player.x_change == 0 and player.y_change == 20 and ((list(map(add,player.position[-1],[20,0])) in player.position) or\n",
    "             player.position[-1][0] + 20 > (game.game_width-20))) or (player.x_change == 0 and player.y_change == -20 and ((list(map(\n",
    "             add, player.position[-1],[-20,0])) in player.position) or player.position[-1][0] - 20 < 20)) or (player.x_change == 20 and player.y_change == 0 and (\n",
    "            (list(map(add,player.position[-1],[0,-20])) in player.position) or player.position[-1][-1] - 20 < 20)) or (\n",
    "            player.x_change == -20 and player.y_change == 0 and ((list(map(add,player.position[-1],[0,20])) in player.position) or\n",
    "            player.position[-1][-1] + 20 >= (game.game_height-20))), #danger left\n",
    "\n",
    "\n",
    "            player.x_change == -20,  # move left\n",
    "            player.x_change == 20,  # move right\n",
    "            player.y_change == -20,  # move up\n",
    "            player.y_change == 20,  # move down\n",
    "            food.x_food < player.x,  # food left\n",
    "            food.x_food > player.x,  # food right\n",
    "            food.y_food < player.y,  # food up\n",
    "            food.y_food > player.y  # food down\n",
    "            ]\n",
    "\n",
    "        for i in range(len(state)):\n",
    "            if state[i]:\n",
    "                state[i]=1\n",
    "            else:\n",
    "                state[i]=0\n",
    "\n",
    "        return np.asarray(state)\n",
    "\n",
    "    def set_reward(self, player, crash):\n",
    "        self.reward = 0\n",
    "        if crash:\n",
    "            self.reward = -10\n",
    "            return self.reward\n",
    "        if player.eaten:\n",
    "            self.reward = 10\n",
    "        return self.reward\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def replay_new(self, memory, batch_size):\n",
    "        if len(memory) > batch_size:\n",
    "            minibatch = random.sample(memory, batch_size)\n",
    "        else:\n",
    "            minibatch = memory\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target = reward + self.gamma * np.amax(self.model.predict(np.array([next_state]))[0])\n",
    "            target_f = self.model.predict(np.array([state]))\n",
    "            target_f[0][np.argmax(action)] = target\n",
    "            self.model.fit(np.array([state]), target_f, epochs=1, verbose=0)\n",
    "\n",
    "    def train_short_memory(self, state, action, reward, next_state, done):\n",
    "        target = reward\n",
    "        if not done:\n",
    "            target = reward + self.gamma * np.amax(self.model.predict(next_state.reshape((1, 11)))[0])\n",
    "        target_f = self.model.predict(state.reshape((1, 11)))\n",
    "        target_f[0][np.argmax(action)] = target\n",
    "        self.model.fit(state.reshape((1, 11)), target_f, epochs=1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pygame in c:\\users\\aryaa\\anaconda3\\lib\\site-packages (1.9.6)\n",
      "Requirement already satisfied: seaborn in c:\\users\\aryaa\\anaconda3\\lib\\site-packages (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\aryaa\\anaconda3\\lib\\site-packages (from seaborn) (1.18.1)\n",
      "Requirement already satisfied: matplotlib>=2.1.2 in c:\\users\\aryaa\\anaconda3\\lib\\site-packages (from seaborn) (3.1.3)\n",
      "Requirement already satisfied: pandas>=0.22.0 in c:\\users\\aryaa\\anaconda3\\lib\\site-packages (from seaborn) (1.0.1)\n",
      "Requirement already satisfied: scipy>=1.0.1 in c:\\users\\aryaa\\anaconda3\\lib\\site-packages (from seaborn) (1.4.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\aryaa\\anaconda3\\lib\\site-packages (from matplotlib>=2.1.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\aryaa\\anaconda3\\lib\\site-packages (from matplotlib>=2.1.2->seaborn) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\aryaa\\anaconda3\\lib\\site-packages (from matplotlib>=2.1.2->seaborn) (2.4.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\aryaa\\anaconda3\\lib\\site-packages (from matplotlib>=2.1.2->seaborn) (1.1.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\aryaa\\anaconda3\\lib\\site-packages (from pandas>=0.22.0->seaborn) (2019.3)\n",
      "Requirement already satisfied: six in c:\\users\\aryaa\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib>=2.1.2->seaborn) (1.14.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\aryaa\\anaconda3\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib>=2.1.2->seaborn) (45.2.0.post20200210)\n"
     ]
    }
   ],
   "source": [
    "!pip install pygame\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--display DISPLAY] [--speed SPEED]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\aryaa\\AppData\\Roaming\\jupyter\\runtime\\kernel-4f1d5bbd-ece5-44ac-b5df-17aa72f7aa0a.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aryaa\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3339: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pygame\n",
    "import argparse\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from DQN import DQNAgent\n",
    "from random import randint\n",
    "from keras.utils import to_categorical\n",
    "import random\n",
    "import statistics\n",
    "\n",
    "#################################\n",
    "#   Define parameters manually  #\n",
    "#################################\n",
    "def define_parameters():\n",
    "    params = dict()\n",
    "    # Neural Network\n",
    "    params['epsilon_decay_linear'] = 1/75\n",
    "    params['learning_rate'] = 0.0005\n",
    "    params['first_layer_size'] = 50   # neurons in the first layer\n",
    "    params['second_layer_size'] = 300   # neurons in the second layer\n",
    "    params['third_layer_size'] = 50    # neurons in the third layer\n",
    "    params['episodes'] = 150           \n",
    "    params['memory_size'] = 2500\n",
    "    params['batch_size'] = 1000\n",
    "    # Settings\n",
    "    params['weights_path'] = 'weights/weights3.hdf5'\n",
    "    params['load_weights'] = False\n",
    "    params['train'] = True\n",
    "    params['plot_score'] = True\n",
    "    return params\n",
    "\n",
    "\n",
    "class Game:\n",
    "    def __init__(self, game_width, game_height):\n",
    "        pygame.display.set_caption('SnakeGen')\n",
    "        self.game_width = game_width\n",
    "        self.game_height = game_height\n",
    "        #self.gameDisplay = pygame.display.set_mode((game_width, game_height + 60))\n",
    "        self.bg = pygame.image.load(\"img/background.png\")\n",
    "        self.crash = False\n",
    "        self.player = Player(self)\n",
    "        self.food = Food()\n",
    "        self.score = 0\n",
    "\n",
    "\n",
    "class Player(object):\n",
    "    def __init__(self, game):\n",
    "        x = 0.45 * game.game_width\n",
    "        y = 0.5 * game.game_height\n",
    "        self.x = x - x % 20\n",
    "        self.y = y - y % 20\n",
    "        self.position = []\n",
    "        self.position.append([self.x, self.y])\n",
    "        self.food = 1\n",
    "        self.eaten = False\n",
    "        self.image = pygame.image.load('img/snakeBody.png')\n",
    "        self.x_change = 20\n",
    "        self.y_change = 0\n",
    "\n",
    "    def update_position(self, x, y):\n",
    "        if self.position[-1][0] != x or self.position[-1][1] != y:\n",
    "            if self.food > 1:\n",
    "                for i in range(0, self.food - 1):\n",
    "                    self.position[i][0], self.position[i][1] = self.position[i + 1]\n",
    "            self.position[-1][0] = x\n",
    "            self.position[-1][1] = y\n",
    "\n",
    "    def do_move(self, move, x, y, game, food, agent):\n",
    "        move_array = [self.x_change, self.y_change]\n",
    "\n",
    "        if self.eaten:\n",
    "            self.position.append([self.x, self.y])\n",
    "            self.eaten = False\n",
    "            self.food = self.food + 1\n",
    "        if np.array_equal(move, [1, 0, 0]):\n",
    "            move_array = self.x_change, self.y_change\n",
    "        elif np.array_equal(move, [0, 1, 0]) and self.y_change == 0:  # right - going horizontal\n",
    "            move_array = [0, self.x_change]\n",
    "        elif np.array_equal(move, [0, 1, 0]) and self.x_change == 0:  # right - going vertical\n",
    "            move_array = [-self.y_change, 0]\n",
    "        elif np.array_equal(move, [0, 0, 1]) and self.y_change == 0:  # left - going horizontal\n",
    "            move_array = [0, -self.x_change]\n",
    "        elif np.array_equal(move, [0, 0, 1]) and self.x_change == 0:  # left - going vertical\n",
    "            move_array = [self.y_change, 0]\n",
    "        self.x_change, self.y_change = move_array\n",
    "        self.x = x + self.x_change\n",
    "        self.y = y + self.y_change\n",
    "\n",
    "        if self.x < 20 or self.x > game.game_width - 40 \\\n",
    "                or self.y < 20 \\\n",
    "                or self.y > game.game_height - 40 \\\n",
    "                or [self.x, self.y] in self.position:\n",
    "            game.crash = True\n",
    "        eat(self, food, game)\n",
    "\n",
    "        self.update_position(self.x, self.y)\n",
    "\n",
    "    def display_player(self, x, y, food, game):\n",
    "        self.position[-1][0] = x\n",
    "        self.position[-1][1] = y\n",
    "\n",
    "        if game.crash == False:\n",
    "            for i in range(food):\n",
    "                x_temp, y_temp = self.position[len(self.position) - 1 - i]\n",
    "                game.gameDisplay.blit(self.image, (x_temp, y_temp))\n",
    "\n",
    "            update_screen()\n",
    "        else:\n",
    "            pygame.time.wait(300)\n",
    "\n",
    "\n",
    "class Food(object):\n",
    "    def __init__(self):\n",
    "        self.x_food = 240\n",
    "        self.y_food = 200\n",
    "        self.image = pygame.image.load('img/food2.png')\n",
    "\n",
    "    def food_coord(self, game, player):\n",
    "        x_rand = randint(20, game.game_width - 40)\n",
    "        self.x_food = x_rand - x_rand % 20\n",
    "        y_rand = randint(20, game.game_height - 40)\n",
    "        self.y_food = y_rand - y_rand % 20\n",
    "        if [self.x_food, self.y_food] not in player.position:\n",
    "            return self.x_food, self.y_food\n",
    "        else:\n",
    "            self.food_coord(game, player)\n",
    "\n",
    "    def display_food(self, x, y, game):\n",
    "        game.gameDisplay.blit(self.image, (x, y))\n",
    "        update_screen()\n",
    "\n",
    "\n",
    "def eat(player, food, game):\n",
    "    if player.x == food.x_food and player.y == food.y_food:\n",
    "        food.food_coord(game, player)\n",
    "        player.eaten = True\n",
    "        game.score = game.score + 1\n",
    "\n",
    "\n",
    "def get_record(score, record):\n",
    "    if score >= record:\n",
    "        return score\n",
    "    else:\n",
    "        return record\n",
    "\n",
    "\n",
    "def display_ui(game, score, record):\n",
    "    myfont = pygame.font.SysFont('Segoe UI', 20)\n",
    "    myfont_bold = pygame.font.SysFont('Segoe UI', 20, True)\n",
    "    text_score = myfont.render('SCORE: ', True, (0, 0, 0))\n",
    "    text_score_number = myfont.render(str(score), True, (0, 0, 0))\n",
    "    text_highest = myfont.render('HIGHEST SCORE: ', True, (0, 0, 0))\n",
    "    text_highest_number = myfont_bold.render(str(record), True, (0, 0, 0))\n",
    "    game.gameDisplay.blit(text_score, (45, 440))\n",
    "    game.gameDisplay.blit(text_score_number, (120, 440))\n",
    "    game.gameDisplay.blit(text_highest, (190, 440))\n",
    "    game.gameDisplay.blit(text_highest_number, (350, 440))\n",
    "    game.gameDisplay.blit(game.bg, (10, 10))\n",
    "\n",
    "\n",
    "def display(player, food, game, record):\n",
    "    game.gameDisplay.fill((255, 255, 255))\n",
    "    display_ui(game, game.score, record)\n",
    "    player.display_player(player.position[-1][0], player.position[-1][1], player.food, game)\n",
    "    food.display_food(food.x_food, food.y_food, game)\n",
    "\n",
    "\n",
    "def update_screen():\n",
    "    pygame.display.update()\n",
    "\n",
    "\n",
    "def initialize_game(player, game, food, agent, batch_size):\n",
    "    state_init1 = agent.get_state(game, player, food)  # [0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0]\n",
    "    action = [1, 0, 0]\n",
    "    player.do_move(action, player.x, player.y, game, food, agent)\n",
    "    state_init2 = agent.get_state(game, player, food)\n",
    "    reward1 = agent.set_reward(player, game.crash)\n",
    "    agent.remember(state_init1, action, reward1, state_init2, game.crash)\n",
    "    agent.replay_new(agent.memory, batch_size)\n",
    "\n",
    "\n",
    "def plot_seaborn(array_counter, array_score,train):\n",
    "    sns.set(color_codes=True, font_scale=1.5)\n",
    "    sns.set_style(\"white\")\n",
    "    plt.figure(figsize=(13,8))\n",
    "    if train==False:\n",
    "        fit_reg = False\n",
    "    ax = sns.regplot(\n",
    "        np.array([array_counter])[0],\n",
    "        np.array([array_score])[0],\n",
    "        #color=\"#36688D\",\n",
    "        x_jitter=.1,\n",
    "        scatter_kws={\"color\": \"#36688D\"},\n",
    "        label='Data',\n",
    "        fit_reg = fit_reg,\n",
    "        line_kws={\"color\": \"#F49F05\"}\n",
    "    )\n",
    "    # Plot the average line\n",
    "    y_mean = [np.mean(array_score)]*len(array_counter)\n",
    "    ax.plot(array_counter,y_mean, label='Mean', linestyle='--')\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.set(xlabel='# games', ylabel='score')\n",
    "    plt.ylim(0,65)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_mean_stdev(array):\n",
    "    return statistics.mean(array), statistics.stdev(array)    \n",
    "\n",
    "\n",
    "def test(display_option, speed, params):\n",
    "    params['load_weights'] = True\n",
    "    params['train'] = False\n",
    "    score, mean, stdev = run(display_option, speed, params)\n",
    "    return score, mean, stdev\n",
    "\n",
    "\n",
    "def run(display_option, speed, params):\n",
    "    pygame.init()\n",
    "    agent = DQNAgent(params)\n",
    "    weights_filepath = params['weights_path']\n",
    "    if params['load_weights']:\n",
    "        agent.model.load_weights(weights_filepath)\n",
    "        print(\"weights loaded\")\n",
    "    counter_games = 0\n",
    "    score_plot = []\n",
    "    counter_plot = []\n",
    "    record = 0\n",
    "    total_score = 0\n",
    "    while counter_games < params['episodes']:\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                pygame.quit()\n",
    "                quit()\n",
    "        # Initialize classes\n",
    "        game = Game(440, 440)\n",
    "        player1 = game.player\n",
    "        food1 = game.food\n",
    "\n",
    "        # Perform first move\n",
    "        initialize_game(player1, game, food1, agent, params['batch_size'])\n",
    "        if display_option:\n",
    "            display(player1, food1, game, record)\n",
    "\n",
    "        while not game.crash:\n",
    "            if not params['train']:\n",
    "                agent.epsilon = 0.00\n",
    "            else:\n",
    "                # agent.epsilon is set to give randomness to actions\n",
    "                agent.epsilon = 1 - (counter_games * params['epsilon_decay_linear'])\n",
    "\n",
    "            # get old state\n",
    "            state_old = agent.get_state(game, player1, food1)\n",
    "\n",
    "            # perform random actions based on agent.epsilon, or choose the action\n",
    "            if random.uniform(0, 1) < agent.epsilon:\n",
    "                final_move = to_categorical(randint(0, 2), num_classes=3)\n",
    "            else:\n",
    "                # predict action based on the old state\n",
    "                prediction = agent.model.predict(state_old.reshape((1, 11)))\n",
    "                final_move = to_categorical(np.argmax(prediction[0]), num_classes=3)\n",
    "\n",
    "            # perform new move and get new state\n",
    "            player1.do_move(final_move, player1.x, player1.y, game, food1, agent)\n",
    "            state_new = agent.get_state(game, player1, food1)\n",
    "\n",
    "            # set reward for the new state\n",
    "            reward = agent.set_reward(player1, game.crash)\n",
    "\n",
    "            if params['train']:\n",
    "                # train short memory base on the new action and state\n",
    "                agent.train_short_memory(state_old, final_move, reward, state_new, game.crash)\n",
    "                # store the new data into a long term memory\n",
    "                agent.remember(state_old, final_move, reward, state_new, game.crash)\n",
    "\n",
    "            record = get_record(game.score, record)\n",
    "            if display_option:\n",
    "                display(player1, food1, game, record)\n",
    "                pygame.time.wait(speed)\n",
    "        if params['train']:\n",
    "            agent.replay_new(agent.memory, params['batch_size'])\n",
    "        counter_games += 1\n",
    "        total_score += game.score\n",
    "        print(f'Game {counter_games}      Score: {game.score}')\n",
    "        score_plot.append(game.score)\n",
    "        counter_plot.append(counter_games)\n",
    "    mean, stdev = get_mean_stdev(score_plot)\n",
    "    if params['train']:\n",
    "        agent.model.save_weights(params['weights_path'])\n",
    "        total_score, mean, stdev = test(display_option, speed, params)\n",
    "    if params['plot_score']:\n",
    "        plot_seaborn(counter_plot, score_plot, params['train'])\n",
    "    print('Total score: {}   Mean: {}   Std dev:   {}'.format(total_score, mean, stdev))\n",
    "    return total_score, mean, stdev\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Set options to activate or deactivate the game view, and its speed\n",
    "    pygame.font.init()\n",
    "    parser = argparse.ArgumentParser()\n",
    "    params = define_parameters()\n",
    "    parser.add_argument(\"--display\", type=bool, default=False)\n",
    "    parser.add_argument(\"--speed\", type=int, default=50)\n",
    "    args = parser.parse_args()\n",
    "    params['bayesian_optimization'] = False    # Use bayesOpt.py for Bayesian Optimization\n",
    "    run(args.display, args.speed, params)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
